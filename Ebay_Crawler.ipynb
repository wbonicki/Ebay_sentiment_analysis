{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extraction\n",
    "\n",
    "This notebook is the first part of the project and contains class used for data acquisition, i.e. downloading products reviews and ratings from ebay which is an e-commerce website (https://www.ebay.com/).\n",
    "The input data was a list containing search words (words that can be entered in a search bar). The products category was mainly focused on electronics and tools. The class returns pandas dataframe consisting of four columns: product category, raw review title, raw review content and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EbayCrawler:\n",
    "    \"\"\"\n",
    "    This class is dedicated for collecting ebay reviews. The final result is pandas dataframe which contains\n",
    "    four columns: category, review title, review content and rating\n",
    "    \n",
    "    The input data consists of search words, having search words defined the functions checks search results with\n",
    "    every given search word and collects products urls that have reviews.\n",
    "    \n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self, search_words, number_of_pages=1):\n",
    "        \"\"\"\n",
    "        the user gives list of search words and the number of pages which will be checked\n",
    "        \"\"\"\n",
    "        if number_of_pages < 1:\n",
    "            raise ValueError('number of pages must be at least 1')\n",
    "        if len(search_words) < 1:\n",
    "            raise ValueError('there must be at least one search word')\n",
    "        \n",
    "        self.search_words = search_words\n",
    "        self.number_of_pages = number_of_pages\n",
    "        self.search_urls = []\n",
    "        self.products_urls = []\n",
    "        self.df = None\n",
    "        \n",
    "        \n",
    "    def search_word_urls(self):\n",
    "        \"\"\"\n",
    "        the method creates urls for every search words\n",
    "        \"\"\"\n",
    "        if not self.search_urls:\n",
    "            print('creating search links...\\n')\n",
    "            for word in self.search_words:\n",
    "                for i in range(1, self.number_of_pages+1):\n",
    "                    url = f'https://www.ebay.com/sch/i.html?_from=R40&_nkw={word}&_sacat=0&_pgn={i}'\n",
    "                    self.search_urls.append(url)\n",
    "                      \n",
    "    def find_products_urls(self, display=True, num_to_display=10):\n",
    "        \"\"\"\n",
    "        the method receives an url with search word results and collects urls of products that have some reviews\n",
    "        \"\"\"\n",
    "        if not self.products_urls:\n",
    "            print('downloading products urls...\\n')\n",
    "            for url in self.search_urls:\n",
    "                soup = BeautifulSoup(requests.get(url).text)\n",
    "                for link in soup.find_all('div', class_='s-item__reviews'):  \n",
    "                    self.products_urls.append(link.a['href'])\n",
    "        if display and self.products_urls != []:\n",
    "            if len(self.products_urls) < num_to_display:\n",
    "                num_to_display = len(self.products_urls)\n",
    "            print(f'Links for the first {num_to_display} products:')\n",
    "            for i in range(num_to_display):\n",
    "                print(self.products_urls[i])\n",
    "                                \n",
    "    @property\n",
    "    def urls_number(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        how many products were found\n",
    "        \"\"\"\n",
    "        return len(self.products_urls) \n",
    "       \n",
    "    def create_reviews_df(self, num_to_download=None, clear=0):\n",
    "        \"\"\"\n",
    "        this method receives a list with products urls and returns one dataframe with reviews and ratings\n",
    "        the user can define how many links will be considered in downloading the reviews\n",
    "        \"\"\" \n",
    "        if clear == 1:\n",
    "            self.df = None\n",
    "        num_of_links = len(self.products_urls)\n",
    "        \n",
    "        if num_to_download is not None:\n",
    "            if num_to_download < len(self.products_urls):\n",
    "                num_of_links = num_to_download\n",
    "                \n",
    "        if self.df is None:\n",
    "            for i, product in enumerate(self.products_urls[:num_of_links], 0):\n",
    "                print(f'downloading {i+1} link from {num_of_links}')\n",
    "                self.df = pd.concat((self.df, EbayCrawler.one_product_reviews(product)))\n",
    "            self.df.set_index(np.arange(self.df.shape[0]), inplace=True)\n",
    "            print('creating dataframe is completed')\n",
    "        else:\n",
    "            print('creating dataframe is completed')\n",
    "    \n",
    "    @classmethod          \n",
    "    def one_product_reviews(cls, url):\n",
    "        \"\"\"\n",
    "        This function returns pandas dataframe with reviews and rating for a given url\n",
    "        \"\"\"\n",
    "\n",
    "        isMore = True\n",
    "        content = requests.get(url).text\n",
    "        soup = BeautifulSoup(content) \n",
    "\n",
    "        #checking if there is a link to the review section (more than 10 reviews)\n",
    "        try:\n",
    "            url = soup.find('div', class_=\"see--all--reviews\").a['href']\n",
    "        except:\n",
    "            isMore = False\n",
    "\n",
    "        category = 'not defined'\n",
    "        try:\n",
    "            category = soup.find('nav', class_='breadcrumb clearfix').text.split('>')[-1]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        #if there is more than 10 reviews\n",
    "        if isMore:\n",
    "            content = requests.get(url).text\n",
    "            soup = BeautifulSoup(content)  \n",
    "\n",
    "\n",
    "            reviews_page_number = len(soup.find_all('a', class_='spf-link'))-2\n",
    "            if reviews_page_number == -2:\n",
    "                return EbayCrawler.ebay_parser(url+'?pgn=1')\n",
    "            else:\n",
    "                for page in range(1, reviews_page_number+1):\n",
    "                    url_temp = url + f'?pgn={page}'\n",
    "                    if page == 1:\n",
    "                        reviews = EbayCrawler.ebay_parser(url_temp, category)\n",
    "                    else:\n",
    "                        reviews = pd.concat((reviews, EbayCrawler.ebay_parser(url_temp, category)))\n",
    "                return reviews\n",
    "\n",
    "        #if there is less than 11 reviews\n",
    "        else:\n",
    "            return EbayCrawler.ebay_parser2(url, category)                \n",
    "                \n",
    "    @staticmethod    \n",
    "    def ebay_parser(url, category=None):\n",
    "        \"\"\"\n",
    "        The function collects all reviews and ratings for a given url if a product has more than one page with reviews\n",
    "        \"\"\"\n",
    "        try:\n",
    "            content = requests.get(url).text\n",
    "        except:\n",
    "            return 'connection failed'\n",
    "\n",
    "        review_data = pd.DataFrame(columns=['category', 'review title', 'review content', 'rating'])\n",
    "\n",
    "        soup = BeautifulSoup(content)\n",
    "        for review, rating_stars in zip(soup.find_all('div',class_='ebay-review-section-r'), soup.find_all('span',class_='star-rating')[1:]):\n",
    "            rating = len(rating_stars.find_all('i', class_='fullStar'))\n",
    "\n",
    "            #checkin if a review has a content and a title - if not it is skipped\n",
    "            if review.p is None or review.h3 is None: \n",
    "                continue\n",
    "            else:\n",
    "                review_data = review_data.append({'category':category, 'review title':review.h3.text, 'review content':review.p.text, 'rating':rating}, ignore_index=True)\n",
    "\n",
    "        return review_data\n",
    "\n",
    "    @staticmethod\n",
    "    def ebay_parser2(url, category=None):\n",
    "        \"\"\"\n",
    "        The function collects all reviews and ratings for a given url if a product has only one page with reviews\n",
    "        \"\"\"\n",
    "        try:\n",
    "            content = requests.get(url).text\n",
    "        except:\n",
    "            return 'connection failed'\n",
    "\n",
    "        review_data = pd.DataFrame(columns=['category', 'review title', 'review content', 'rating'])\n",
    "\n",
    "        soup = BeautifulSoup(content)\n",
    "\n",
    "        for review, rating_stars in zip(soup.find_all('div',class_='review--section--r'), soup.find_all('div',class_='review--section--l')):\n",
    "            rating = rating_stars.span.text[0]\n",
    "            review_data = review_data.append({'category':category, 'review title':review.h4.text, 'review content':review.p.text, 'rating':rating}, ignore_index=True)\n",
    "\n",
    "        return review_data\n",
    "    \n",
    "    def save_to_csv(self, file_name, **kwargs):\n",
    "        \"\"\"\n",
    "        saving created dataframe to csv file\n",
    "        \"\"\"\n",
    "        if self.df is None:\n",
    "            raise ValueError('dataframe needs to be created')\n",
    "        else:\n",
    "            self.df.to_csv(file_name,**kwargs)\n",
    "            print('dataframe saved to csv file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example showing how to use the class\n",
    "note: the instance below was not used for reviews used in the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an instance of a class with a list with search words\n",
    "#and number of pages that are going to be searched\n",
    "electronics = EbayCrawler(['apple', 'samsung', 'huawei'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating search links...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#creating urls for every given search word\n",
    "electronics.search_word_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.ebay.com/sch/i.html?_from=R40&_nkw=apple&_sacat=0&_pgn=1',\n",
       " 'https://www.ebay.com/sch/i.html?_from=R40&_nkw=apple&_sacat=0&_pgn=2',\n",
       " 'https://www.ebay.com/sch/i.html?_from=R40&_nkw=apple&_sacat=0&_pgn=3',\n",
       " 'https://www.ebay.com/sch/i.html?_from=R40&_nkw=apple&_sacat=0&_pgn=4',\n",
       " 'https://www.ebay.com/sch/i.html?_from=R40&_nkw=apple&_sacat=0&_pgn=5']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the first five search links\n",
    "electronics.search_urls[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading products urls...\n",
      "\n",
      "Links for the first 5 products:\n",
      "https://www.ebay.com/p/9033147853?iid=143991207255&var=443268613630#UserReviews\n",
      "https://www.ebay.com/p/239086499?iid=174105091978&var=472963059163#UserReviews\n",
      "https://www.ebay.com/p/28035914224?iid=153638834105&var=453955077521#UserReviews\n",
      "https://www.ebay.com/p/21039165430?iid=143966345913&var=443233867014#UserReviews\n",
      "https://www.ebay.com/p/23041724003?iid=154155769769&var=454287744559#UserReviews\n"
     ]
    }
   ],
   "source": [
    "#downloading ulrs of products that has reviews\n",
    "electronics.find_products_urls(display=True, num_to_display=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a total number of found urls\n",
    "electronics.urls_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading 1 link from 5\n",
      "downloading 2 link from 5\n",
      "downloading 3 link from 5\n",
      "downloading 4 link from 5\n",
      "downloading 5 link from 5\n",
      "creating dataframe is completed\n"
     ]
    }
   ],
   "source": [
    "#creating dataframe\n",
    "electronics.create_reviews_df(num_to_download=5, clear=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>review title</th>\n",
       "      <th>review content</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cell Phones &amp; Smartphones</td>\n",
       "      <td>Lightweight very reliable phone with great fea...</td>\n",
       "      <td>Great phone at a great price! It came looking ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cell Phones &amp; Smartphones</td>\n",
       "      <td>broken camera, otherwise great</td>\n",
       "      <td>phone works pretty well only problem is the fr...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cell Phones &amp; Smartphones</td>\n",
       "      <td>great phone for the price</td>\n",
       "      <td>very light ... easy to use ..many features i w...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cell Phones &amp; Smartphones</td>\n",
       "      <td>Looks brand new!!!</td>\n",
       "      <td>Given as a Xmas gift for my 13 year old. His f...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cell Phones &amp; Smartphones</td>\n",
       "      <td>Great phone for the price</td>\n",
       "      <td>I needed a second iPhone for use international...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    category  \\\n",
       "0  Cell Phones & Smartphones   \n",
       "1  Cell Phones & Smartphones   \n",
       "2  Cell Phones & Smartphones   \n",
       "3  Cell Phones & Smartphones   \n",
       "4  Cell Phones & Smartphones   \n",
       "\n",
       "                                        review title  \\\n",
       "0  Lightweight very reliable phone with great fea...   \n",
       "1                     broken camera, otherwise great   \n",
       "2                          great phone for the price   \n",
       "3                                 Looks brand new!!!   \n",
       "4                          Great phone for the price   \n",
       "\n",
       "                                      review content rating  \n",
       "0  Great phone at a great price! It came looking ...      5  \n",
       "1  phone works pretty well only problem is the fr...      2  \n",
       "2  very light ... easy to use ..many features i w...      5  \n",
       "3  Given as a Xmas gift for my 13 year old. His f...      5  \n",
       "4  I needed a second iPhone for use international...      5  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electronics.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe saved to csv file\n"
     ]
    }
   ],
   "source": [
    "#saving dataframe to csv file, a user can give some additional options regaridng saving options\n",
    "electronics.save_to_csv('test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
