{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extraction\n",
    "\n",
    "This notebook is the first part of the project and contains class used for data acquisition, i.e. downloading products reviews and ratings from ebay which is an e-commerce website (https://www.ebay.com/).\n",
    "The input data was a list containing search words (words that can be entered in a search bar). The products category was mainly focused on electronics and tools. The class returns pandas dataframe consisting of four columns: product category, raw review title, raw review content and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EbayCrawler:\n",
    "    \"\"\"\n",
    "    This class is dedicated for collecting ebay reviews.\n",
    "    The final result is pandas dataframe which contains\n",
    "    four columns: category, review title, review content and rating\n",
    "\n",
    "    The input data consists of search words, having search words\n",
    "    defined the functions checks search results with\n",
    "    every given search word and collects products urls that have reviews.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, search_words, number_of_pages=1):\n",
    "        \"\"\"\n",
    "        the user gives list of search words and the number of pages\n",
    "        which will be checked\n",
    "        \"\"\"\n",
    "        if number_of_pages < 1:\n",
    "            raise ValueError('number of pages must be at least 1')\n",
    "        if len(search_words) < 1:\n",
    "            raise ValueError('there must be at least one search word')\n",
    "\n",
    "        self.search_words = search_words\n",
    "        self.number_of_pages = number_of_pages\n",
    "        self.search_urls = []\n",
    "        self.products_urls = []\n",
    "        self.df = None\n",
    "\n",
    "    def search_word_urls(self):\n",
    "        \"\"\"\n",
    "        the method creates urls for every search words\n",
    "        \"\"\"\n",
    "        if not self.search_urls:\n",
    "            print('creating search links...\\n')\n",
    "            for word in self.search_words:\n",
    "                for i in range(1, self.number_of_pages+1):\n",
    "                    url = f'https://www.ebay.com/sch/i.html?_from=R40&_nkw' \\\n",
    "                            f'={word}&_sacat=0&_pgn={i}'\n",
    "                    self.search_urls.append(url)\n",
    "\n",
    "    def find_products_urls(self, display=True, num_to_display=10):\n",
    "        \"\"\"\n",
    "        the method receives an url with search word results and\n",
    "        collects urls of products that have some reviews\n",
    "        \"\"\"\n",
    "        if not self.products_urls:\n",
    "            print('downloading products urls...\\n')\n",
    "            for url in self.search_urls:\n",
    "                soup = BeautifulSoup(requests.get(url).text)\n",
    "                for link in soup.find_all('div', class_='s-item__reviews'):\n",
    "                    self.products_urls.append(link.a['href'])\n",
    "        if display and self.products_urls != []:\n",
    "            if len(self.products_urls) < num_to_display:\n",
    "                num_to_display = len(self.products_urls)\n",
    "            print(f'Links for the first {num_to_display} products:')\n",
    "            for i in range(num_to_display):\n",
    "                print(self.products_urls[i])\n",
    "\n",
    "    @property\n",
    "    def urls_number(self):\n",
    "\n",
    "        \"\"\"\n",
    "        how many products were found\n",
    "        \"\"\"\n",
    "        return len(self.products_urls)\n",
    "\n",
    "    def create_reviews_df(self, num_to_download=None, clear=0):\n",
    "        \"\"\"\n",
    "        this method receives a list with products urls and returns one\n",
    "        dataframe with reviews and ratings the user can define how many\n",
    "        links will be considered in downloading the reviews\n",
    "        \"\"\"\n",
    "        if clear == 1:\n",
    "            self.df = None\n",
    "        num_of_links = len(self.products_urls)\n",
    "\n",
    "        if num_to_download is not None:\n",
    "            if num_to_download < len(self.products_urls):\n",
    "                num_of_links = num_to_download\n",
    "\n",
    "        if self.df is None:\n",
    "            for i, product in enumerate(self.products_urls[:num_of_links], 0):\n",
    "                print(f'downloading {i+1} link from {num_of_links}')\n",
    "                self.df = pd.concat(\n",
    "                    (self.df, EbayCrawler.one_product_reviews(product))\n",
    "                    )\n",
    "            self.df.set_index(np.arange(self.df.shape[0]), inplace=True)\n",
    "            print('creating dataframe is completed')\n",
    "        else:\n",
    "            print('creating dataframe is completed')\n",
    "\n",
    "    @classmethod\n",
    "    def one_product_reviews(cls, url):\n",
    "        \"\"\"\n",
    "        This function returns pandas dataframe with reviews and rating\n",
    "        for a given url\n",
    "        \"\"\"\n",
    "\n",
    "        isMore = True\n",
    "        content = requests.get(url).text\n",
    "        soup = BeautifulSoup(content)\n",
    "\n",
    "        # checking if there is a link to the review section\n",
    "        # (more than 10 reviews)\n",
    "        try:\n",
    "            url = soup.find('div', class_=\"see--all--reviews\").a['href']\n",
    "        except:\n",
    "            isMore = False\n",
    "\n",
    "        category = 'not defined'\n",
    "        try:\n",
    "            category = soup.find('nav', class_='breadcrumb clearfix') \\\n",
    "                       .text.split('>')[-1]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # if there is more than 10 reviews\n",
    "        if isMore:\n",
    "            content = requests.get(url).text\n",
    "            soup = BeautifulSoup(content)\n",
    "\n",
    "            reviews_page_number = len(soup.find_all('a', class_='spf-link'))-2\n",
    "            if reviews_page_number == -2:\n",
    "                return EbayCrawler.ebay_parser(url+'?pgn=1')\n",
    "            else:\n",
    "                for page in range(1, reviews_page_number+1):\n",
    "                    url_temp = url + f'?pgn={page}'\n",
    "                    if page == 1:\n",
    "                        reviews = EbayCrawler.ebay_parser(url_temp, category)\n",
    "                    else:\n",
    "                        reviews = pd.concat((\n",
    "                            reviews, EbayCrawler.ebay_parser(url_temp, category)\n",
    "                            ))\n",
    "                return reviews\n",
    "\n",
    "        # if there is less than 11 reviews\n",
    "        else:\n",
    "            return EbayCrawler.ebay_parser2(url, category)\n",
    "\n",
    "    @staticmethod\n",
    "    def ebay_parser(url, category=None):\n",
    "        \"\"\"\n",
    "        The function collects all reviews and ratings for a given url if a\n",
    "        product has more than one page with reviews\n",
    "        \"\"\"\n",
    "        try:\n",
    "            content = requests.get(url).text\n",
    "        except:\n",
    "            return 'connection failed'\n",
    "\n",
    "        review_data = pd.DataFrame(\n",
    "            columns=['category', 'review title', 'review content', 'rating']\n",
    "            )\n",
    "\n",
    "        soup = BeautifulSoup(content)\n",
    "        for review, rating_stars in zip(\n",
    "            soup.find_all('div', class_='ebay-review-section-r'),\n",
    "            soup.find_all('span', class_='star-rating')[1:]\n",
    "        ):\n",
    "\n",
    "            rating = len(rating_stars.find_all('i', class_='fullStar'))\n",
    "\n",
    "            # checkin if a review has a content and a title\n",
    "            # if not it is skipped\n",
    "            if review.p is None or review.h3 is None:\n",
    "                continue\n",
    "            else:\n",
    "                review_data = review_data.append(\n",
    "                    {\n",
    "                        'category': category,\n",
    "                        'review title': review.h3.text,\n",
    "                        'review content': review.p.text,\n",
    "                        'rating': rating\n",
    "                    },\n",
    "                    ignore_index=True\n",
    "                )\n",
    "\n",
    "        return review_data\n",
    "\n",
    "    @staticmethod\n",
    "    def ebay_parser2(url, category=None):\n",
    "        \"\"\"\n",
    "        The function collects all reviews and ratings for a given url\n",
    "        if a product has only one page with reviews\n",
    "        \"\"\"\n",
    "        try:\n",
    "            content = requests.get(url).text\n",
    "        except:\n",
    "            return 'connection failed'\n",
    "\n",
    "        review_data = pd.DataFrame(columns=[\n",
    "            'category', 'review title', 'review content', 'rating'\n",
    "            ])\n",
    "\n",
    "        soup = BeautifulSoup(content)\n",
    "\n",
    "        for review, rating_stars in zip(\n",
    "            soup.find_all('div', class_='review--section--r'),\n",
    "            soup.find_all('div', class_='review--section--l')\n",
    "        ):\n",
    "            rating = rating_stars.span.text[0]\n",
    "            review_data = review_data.append(\n",
    "                {\n",
    "                    'category': category,\n",
    "                    'review title': review.h4.text,\n",
    "                    'review content': review.p.text,\n",
    "                    'rating': rating\n",
    "                },\n",
    "                ignore_index=True\n",
    "            )\n",
    "\n",
    "        return review_data\n",
    "\n",
    "    def save_to_csv(self, file_name, **kwargs):\n",
    "        \"\"\"\n",
    "        saving created dataframe to csv file\n",
    "        \"\"\"\n",
    "        if self.df is None:\n",
    "            raise ValueError('dataframe needs to be created')\n",
    "        else:\n",
    "            self.df.to_csv(file_name, **kwargs)\n",
    "            print('dataframe saved to csv file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example showing how to use the class\n",
    "note: the instance below was not used for reviews used in the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an instance of a class with a list with search words\n",
    "#and number of pages that are going to be searched\n",
    "electronics = EbayCrawler(['apple', 'samsung', 'huawei'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating search links...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#creating urls for every given search word\n",
    "electronics.search_word_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.ebay.com/sch/i.html?_from=R40&_nkw=apple&_sacat=0&_pgn=1',\n",
       " 'https://www.ebay.com/sch/i.html?_from=R40&_nkw=apple&_sacat=0&_pgn=2',\n",
       " 'https://www.ebay.com/sch/i.html?_from=R40&_nkw=apple&_sacat=0&_pgn=3',\n",
       " 'https://www.ebay.com/sch/i.html?_from=R40&_nkw=apple&_sacat=0&_pgn=4',\n",
       " 'https://www.ebay.com/sch/i.html?_from=R40&_nkw=apple&_sacat=0&_pgn=5']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the first five search links\n",
    "electronics.search_urls[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading products urls...\n",
      "\n",
      "Links for the first 5 products:\n",
      "https://www.ebay.com/p/4018215500?iid=174105091978&var=472963059163#UserReviews\n",
      "https://www.ebay.com/p/23024045643?iid=114711167770&var=414867589699#UserReviews\n",
      "https://www.ebay.com/p/3033813445?iid=113652223677&var=413778701567&rt=nc#UserReviews\n",
      "https://www.ebay.com/p/9040885904?iid=313512124902#UserReviews\n",
      "https://www.ebay.com/p/2305260683?iid=293463314986&var=592274477604#UserReviews\n"
     ]
    }
   ],
   "source": [
    "#downloading ulrs of products that has reviews\n",
    "electronics.find_products_urls(display=True, num_to_display=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "385"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a total number of found urls\n",
    "electronics.urls_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading 1 link from 5\n",
      "downloading 2 link from 5\n",
      "downloading 3 link from 5\n",
      "downloading 4 link from 5\n",
      "downloading 5 link from 5\n",
      "creating dataframe is completed\n"
     ]
    }
   ],
   "source": [
    "#creating dataframe\n",
    "electronics.create_reviews_df(num_to_download=5, clear=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>review title</th>\n",
       "      <th>review content</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cell Phones &amp; Smartphones</td>\n",
       "      <td>This product is in a league by itself.</td>\n",
       "      <td>Semi easy to swap SIM card and unknown futuris...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cell Phones &amp; Smartphones</td>\n",
       "      <td>Great phone!</td>\n",
       "      <td>The I phone 8 looked brand new,\\nGlad I made t...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cell Phones &amp; Smartphones</td>\n",
       "      <td>I Phone 8 plus is Good Phone. It has great fea...</td>\n",
       "      <td>I Phone 8 Plus is a very good phone. It is bet...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cell Phones &amp; Smartphones</td>\n",
       "      <td>Wish it didn’t cause me headaches.</td>\n",
       "      <td>Many positives: feels good in hand, pleasing d...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cell Phones &amp; Smartphones</td>\n",
       "      <td>Pleased with my previously used Apple i-Phone 8</td>\n",
       "      <td>I was pleasantly surprised with the rapid ship...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    category  \\\n",
       "0  Cell Phones & Smartphones   \n",
       "1  Cell Phones & Smartphones   \n",
       "2  Cell Phones & Smartphones   \n",
       "3  Cell Phones & Smartphones   \n",
       "4  Cell Phones & Smartphones   \n",
       "\n",
       "                                        review title  \\\n",
       "0             This product is in a league by itself.   \n",
       "1                                       Great phone!   \n",
       "2  I Phone 8 plus is Good Phone. It has great fea...   \n",
       "3                 Wish it didn’t cause me headaches.   \n",
       "4    Pleased with my previously used Apple i-Phone 8   \n",
       "\n",
       "                                      review content rating  \n",
       "0  Semi easy to swap SIM card and unknown futuris...      5  \n",
       "1  The I phone 8 looked brand new,\\nGlad I made t...      5  \n",
       "2  I Phone 8 Plus is a very good phone. It is bet...      5  \n",
       "3  Many positives: feels good in hand, pleasing d...      2  \n",
       "4  I was pleasantly surprised with the rapid ship...      4  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electronics.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe saved to csv file\n"
     ]
    }
   ],
   "source": [
    "#saving dataframe to csv file, a user can give some additional options regaridng saving options\n",
    "electronics.save_to_csv('test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
