{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extraction\n",
    "\n",
    "This notebook is the first part of the project and contains class used for data acquisition, i.e. downloading products reviews and ratings from ebay which is an e-commerce website (https://www.ebay.com/).\n",
    "The input data was a list containing search words (words that can be entered in a search bar). The products category was mainly focused on electronics and tools. The class returns pandas dataframe consisting of four columns: product category, raw review title, raw review content and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EbayCrawler:\n",
    "    \"\"\"\n",
    "    This class is dedicated for collecting ebay reviews.\n",
    "    The final result is pandas dataframe which contains four columns:\n",
    "    category, review title, review content and rating\n",
    "\n",
    "    The input data consists of search words,\n",
    "    having search words defined the functions checks search results with\n",
    "    every given search word and collects products urls that have reviews.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, search_words, number_of_pages=1):\n",
    "        \"\"\"\n",
    "        A user gives list of search words and the number of pages\n",
    "        which will be checked\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        search_word : list, default None\n",
    "        List with search words that can be put in ebay search bar,\n",
    "        for example search_words = ['apple', 'huawei', 'samsung']\n",
    "        \n",
    "        number_of_pages : int, default 1\n",
    "        How many pages with every search word will be search in\n",
    "        order to find products with reviews\n",
    "        \n",
    "        \"\"\"\n",
    "        if number_of_pages < 1:\n",
    "            raise ValueError(\"number of pages must be at least 1\")\n",
    "        if len(search_words) < 1:\n",
    "            raise ValueError(\"there must be at least one search word\")\n",
    "\n",
    "        self.search_words = search_words\n",
    "        self.number_of_pages = number_of_pages\n",
    "        self.search_urls = []\n",
    "        self.products_urls = []\n",
    "        self.df = None\n",
    "\n",
    "    def __add__(self, other_df):\n",
    "        \"\"\"\n",
    "        Addition operation is implemented\n",
    "        \"\"\"\n",
    "        if not isinstance(other_df, pd.core.frame.DataFrame) \\\n",
    "        and not isinstance(other_df, EbayCrawler):\n",
    "            raise TypeError(\n",
    "                \"Cannot perform add operation on different types\" \\\n",
    "                \"The other type must be pandas data frame or an \" \\\n",
    "                \"instance of EbayCrawler\")\n",
    "        else:\n",
    "            if self.df is None:\n",
    "                return other_df\n",
    "            else:\n",
    "                if isinstance(other_df, pd.core.frame.DataFrame):\n",
    "                    if self.df.shape[1] != other_df.shape[1]:\n",
    "                        raise ValueError(\n",
    "                            \"Dimensions of each dataframe must match\")\n",
    "                    self.df = pd.concat([self.df, other_df])\n",
    "                    self.df.reset_index(drop=True, inplace=True)\n",
    "                else:\n",
    "                    if self.df.shape[1] != other_df.df.shape[1]:\n",
    "                        raise ValueError(\n",
    "                            \"Dimensions of each dataframe must match\")\n",
    "                    self.df = pd.concat([self.df, other_df.df])\n",
    "                    self.df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    def search_word_urls(self):\n",
    "        \"\"\"\n",
    "        Method that creates urls for every search words\n",
    "        \"\"\"\n",
    "        if not self.search_urls:\n",
    "            print('creating search links...\\n')\n",
    "            for word in self.search_words:\n",
    "                for i in range(1, self.number_of_pages+1):\n",
    "                    url = f'https://www.ebay.com/sch/i.html?_from=R40&_nkw' \\\n",
    "                          f'={word}&_sacat=0&_pgn={i}'\n",
    "                    self.search_urls.append(url)\n",
    "\n",
    "    def find_products_urls(self, display=True, num_to_display=10):\n",
    "        \"\"\"\n",
    "        Method that receives an url with search word results and\n",
    "        collects urls of products that have some reviews\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        display : boolean, default True\n",
    "        If True the method shows products urls\n",
    "        \n",
    "        num_to_display : int, default 10\n",
    "        If display is True, the number of url which will be shown\n",
    "        \n",
    "        \"\"\"\n",
    "        if not self.products_urls:\n",
    "            print('downloading products urls...\\n')\n",
    "            for url in self.search_urls:\n",
    "                soup = BeautifulSoup(requests.get(url).text)\n",
    "                for link in soup.find_all('div', class_='s-item__reviews'):\n",
    "                    self.products_urls.append(link.a['href'])\n",
    "        if display and self.products_urls != []:\n",
    "            if len(self.products_urls) < num_to_display:\n",
    "                num_to_display = len(self.products_urls)\n",
    "            print(f'Links for the first {num_to_display} products:')\n",
    "            for i in range(num_to_display):\n",
    "                print(self.products_urls[i])\n",
    "        print('downloading finished\\n')\n",
    "\n",
    "    @property\n",
    "    def urls_number(self):\n",
    "        \"Property that shows number of found products with reviews\"\n",
    "        return len(self.products_urls)\n",
    "\n",
    "    def create_reviews_df(self, num_to_download=None, clear=True):\n",
    "        \"\"\"\n",
    "        Method that receives a list with products urls and returns one\n",
    "        dataframe with reviews and ratings. The user can define how many\n",
    "        links will be considered in downloading the reviews\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        num_to_download : int, default None\n",
    "        Number of links which will provide reviews,\n",
    "        for example if the instance found 1000 links it will take much time,\n",
    "        the user may want to collect the first 10 links. If no number is given\n",
    "        the method collects all of the links\n",
    "        \n",
    "        \n",
    "        clear : boolean, default False\n",
    "        If False instance dataframe is deleted and becomes None. The method\n",
    "        may be used again for downloading reviews.\n",
    "        \n",
    "        \"\"\"\n",
    "        if not clear:\n",
    "            self.df = None\n",
    "        num_of_links = len(self.products_urls)\n",
    "\n",
    "        if num_to_download is not None:\n",
    "            if num_to_download < len(self.products_urls):\n",
    "                num_of_links = num_to_download\n",
    "\n",
    "        if self.df is None:\n",
    "            for i, product in enumerate(self.products_urls[:num_of_links], 0):\n",
    "                print(f'downloading {i+1} link from {num_of_links}')\n",
    "                self.df = pd.concat(\n",
    "                    (self.df, EbayCrawler.one_product_reviews(product))\n",
    "                    )\n",
    "            self.df.set_index(np.arange(self.df.shape[0]), inplace=True)\n",
    "            print('creating dataframe is completed')\n",
    "        else:\n",
    "            print('creating dataframe is completed')\n",
    "\n",
    "    @classmethod\n",
    "    def one_product_reviews(cls, url):\n",
    "        \"\"\"\n",
    "        Class method that returns pandas dataframe with reviews and rating\n",
    "        for a given url\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        url : string\n",
    "        Url with product that has reviews\n",
    "        \"\"\"\n",
    "\n",
    "        isMore = True\n",
    "        content = requests.get(url).text\n",
    "        soup = BeautifulSoup(content)\n",
    "\n",
    "        # checking if there is a link to the review section\n",
    "        # (more than 10 reviews)\n",
    "        try:\n",
    "            url = soup.find('div', class_=\"see--all--reviews\").a['href']\n",
    "        except:\n",
    "            isMore = False\n",
    "\n",
    "        category = 'not defined'\n",
    "        try:\n",
    "            category = soup.find('nav', class_='breadcrumb clearfix') \\\n",
    "                       .text.split('>')[-1]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # if there is more than 10 reviews\n",
    "        if isMore:\n",
    "            content = requests.get(url).text\n",
    "            soup = BeautifulSoup(content)\n",
    "\n",
    "            reviews_page_number = len(soup.find_all('a', class_='spf-link'))-2\n",
    "            if reviews_page_number == -2:\n",
    "                return EbayCrawler.ebay_parser(url+'?pgn=1')\n",
    "            else:\n",
    "                for page in range(1, reviews_page_number+1):\n",
    "                    url_temp = url + f'?pgn={page}'\n",
    "                    if page == 1:\n",
    "                        reviews = EbayCrawler.ebay_parser(url_temp, category)\n",
    "                    else:\n",
    "                        reviews = pd.concat((\n",
    "                            reviews, EbayCrawler.ebay_parser(url_temp, category)\n",
    "                            ))\n",
    "                return reviews\n",
    "\n",
    "        # if there is less than 11 reviews\n",
    "        else:\n",
    "            return EbayCrawler.ebay_parser2(url, category)\n",
    "\n",
    "    @staticmethod\n",
    "    def ebay_parser(url, category=None):\n",
    "        \"\"\"\n",
    "        Staticmethod that collects all of the reviews and ratings\n",
    "        for a given url if a product has more than one page with reviews\n",
    "        \"\"\"\n",
    "        try:\n",
    "            content = requests.get(url).text\n",
    "        except:\n",
    "            return 'connection failed'\n",
    "\n",
    "        review_data = pd.DataFrame(\n",
    "            columns=['category', 'review title', 'review content', 'rating']\n",
    "            )\n",
    "\n",
    "        soup = BeautifulSoup(content)\n",
    "        for review, rating_stars in zip(\n",
    "            soup.find_all('div', class_='ebay-review-section-r'),\n",
    "            soup.find_all('span', class_='star-rating')[1:]\n",
    "        ):\n",
    "\n",
    "            rating = len(rating_stars.find_all('i', class_='fullStar'))\n",
    "\n",
    "            # checkin if a review has a content and a title\n",
    "            # if not it is skipped\n",
    "            if review.p is None or review.h3 is None:\n",
    "                continue\n",
    "            else:\n",
    "                review_data = review_data.append(\n",
    "                    {\n",
    "                        'category': category,\n",
    "                        'review title': review.h3.text,\n",
    "                        'review content': review.p.text,\n",
    "                        'rating': rating\n",
    "                    },\n",
    "                    ignore_index=True\n",
    "                )\n",
    "\n",
    "        return review_data\n",
    "\n",
    "    @staticmethod\n",
    "    def ebay_parser2(url, category=None):\n",
    "        \"\"\"\n",
    "        Staticmethod that collects all of the reviews and ratings\n",
    "        for a given url if a product has only one page with reviews\n",
    "        \"\"\"\n",
    "        try:\n",
    "            content = requests.get(url).text\n",
    "        except:\n",
    "            return 'connection failed'\n",
    "\n",
    "        review_data = pd.DataFrame(columns=[\n",
    "            'category', 'review title', 'review content', 'rating'\n",
    "            ])\n",
    "\n",
    "        soup = BeautifulSoup(content)\n",
    "\n",
    "        for review, rating_stars in zip(\n",
    "            soup.find_all('div', class_='review--section--r'),\n",
    "            soup.find_all('div', class_='review--section--l')\n",
    "        ):\n",
    "            rating = rating_stars.span.text[0]\n",
    "            review_data = review_data.append(\n",
    "                {\n",
    "                    'category': category,\n",
    "                    'review title': review.h4.text,\n",
    "                    'review content': review.p.text,\n",
    "                    'rating': rating\n",
    "                },\n",
    "                ignore_index=True\n",
    "            )\n",
    "\n",
    "        return review_data\n",
    "\n",
    "    def save_to_csv(self, file_name, **kwargs):\n",
    "        \"\"\"\n",
    "        Saving created dataframe to csv file\n",
    "         \n",
    "        Parameters\n",
    "        ----------\n",
    "        file_name : string\n",
    "        Name of the file to which dataframe will be saved\n",
    "        \n",
    "        **kwargs\n",
    "        Arguments for pandas to_csv method\n",
    "        \"\"\"\n",
    "        if self.df is None:\n",
    "            raise ValueError('dataframe needs to be created')\n",
    "        else:\n",
    "            self.df.to_csv(file_name, **kwargs)\n",
    "            print('dataframe saved to csv file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example showing how to use the class\n",
    "note: the instance below was not used for reviews used in the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an instance of a class with a list with search words\n",
    "# and number of pages that are going to be searched\n",
    "electronics = EbayCrawler(['apple', 'samsung'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating search links...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating urls for every given search word\n",
    "electronics.search_word_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.ebay.com/sch/i.html?_from=R40&_nkw=apple&_sacat=0&_pgn=1',\n",
       " 'https://www.ebay.com/sch/i.html?_from=R40&_nkw=apple&_sacat=0&_pgn=2',\n",
       " 'https://www.ebay.com/sch/i.html?_from=R40&_nkw=apple&_sacat=0&_pgn=3',\n",
       " 'https://www.ebay.com/sch/i.html?_from=R40&_nkw=apple&_sacat=0&_pgn=4',\n",
       " 'https://www.ebay.com/sch/i.html?_from=R40&_nkw=apple&_sacat=0&_pgn=5']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the first five search links\n",
    "electronics.search_urls[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading products urls...\n",
      "\n",
      "Links for the first 5 products:\n",
      "https://www.ebay.com/p/19034211488?iid=154462877777&var=454530222702#UserReviews\n",
      "https://www.ebay.com/p/4018215500?iid=174105091978&var=472963059163#UserReviews\n",
      "https://www.ebay.com/p/15022478164?iid=274505797468&var=574685374492#UserReviews\n",
      "https://www.ebay.com/p/3033813445?iid=113652223677&var=413778701567&rt=nc#UserReviews\n",
      "https://www.ebay.com/p/23024045643?iid=114711167770&var=414867589699#UserReviews\n",
      "downloading finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# downloading ulrs of products that have reviews\n",
    "# the first five link are displayed\n",
    "electronics.find_products_urls(display=True, num_to_display=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a total number of found urls\n",
    "electronics.urls_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading 1 link from 2\n",
      "downloading 2 link from 2\n",
      "creating dataframe is completed\n"
     ]
    }
   ],
   "source": [
    "# creating dataframe\n",
    "# reviews are downloaded from the first two links\n",
    "electronics.create_reviews_df(num_to_download=2, clear=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>review title</th>\n",
       "      <th>review content</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cell Phones &amp; Smartphones</td>\n",
       "      <td>Great Phone, But Repetitive Design</td>\n",
       "      <td>The iPhone 11 Pro Max continues to showcase Ap...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cell Phones &amp; Smartphones</td>\n",
       "      <td>Smooth and fast</td>\n",
       "      <td>Like any new wave of Apple product, this is ea...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cell Phones &amp; Smartphones</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>Absolutely love it ,perfect new condition flaw...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cell Phones &amp; Smartphones</td>\n",
       "      <td>Smokin fast</td>\n",
       "      <td>Great phone. User friendly, super fast, long l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cell Phones &amp; Smartphones</td>\n",
       "      <td>Great phone</td>\n",
       "      <td>It all I wanted and now I wouldn’t trade it fo...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    category                        review title  \\\n",
       "0  Cell Phones & Smartphones  Great Phone, But Repetitive Design   \n",
       "1  Cell Phones & Smartphones                     Smooth and fast   \n",
       "2  Cell Phones & Smartphones                            Awesome    \n",
       "3  Cell Phones & Smartphones                         Smokin fast   \n",
       "4  Cell Phones & Smartphones                         Great phone   \n",
       "\n",
       "                                      review content rating  \n",
       "0  The iPhone 11 Pro Max continues to showcase Ap...      5  \n",
       "1  Like any new wave of Apple product, this is ea...      5  \n",
       "2  Absolutely love it ,perfect new condition flaw...      5  \n",
       "3  Great phone. User friendly, super fast, long l...      5  \n",
       "4  It all I wanted and now I wouldn’t trade it fo...      5  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final dataframe\n",
    "electronics.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In class operation of addition is implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating search links...\n",
      "\n",
      "downloading products urls...\n",
      "\n",
      "downloading finished\n",
      "\n",
      "downloading 1 link from 5\n",
      "downloading 2 link from 5\n",
      "downloading 3 link from 5\n",
      "downloading 4 link from 5\n",
      "downloading 5 link from 5\n",
      "creating dataframe is completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>review title</th>\n",
       "      <th>review content</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cell Phones &amp; Smartphones</td>\n",
       "      <td>Would Reccomend even without Google.</td>\n",
       "      <td>Great fit in your hand great Battery life, Per...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cell Phones &amp; Smartphones</td>\n",
       "      <td>The best bang for your buck!</td>\n",
       "      <td>I do have a couple of small issues with the P2...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cell Phones &amp; Smartphones</td>\n",
       "      <td>Amazing</td>\n",
       "      <td>Two small problems: 1. The phone came started ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cell Phones &amp; Smartphones</td>\n",
       "      <td>Very Reliable phone.</td>\n",
       "      <td>This is our 2nd Wuawei phone.  I got a mate 9 ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cell Phones &amp; Smartphones</td>\n",
       "      <td>More than I expected</td>\n",
       "      <td>Amazing product! Took a chance on an unfamilia...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    category                           review title  \\\n",
       "0  Cell Phones & Smartphones  Would Reccomend even without Google.    \n",
       "1  Cell Phones & Smartphones           The best bang for your buck!   \n",
       "2  Cell Phones & Smartphones                                Amazing   \n",
       "3  Cell Phones & Smartphones                   Very Reliable phone.   \n",
       "4  Cell Phones & Smartphones                   More than I expected   \n",
       "\n",
       "                                      review content rating  \n",
       "0  Great fit in your hand great Battery life, Per...      5  \n",
       "1  I do have a couple of small issues with the P2...      5  \n",
       "2  Two small problems: 1. The phone came started ...      5  \n",
       "3  This is our 2nd Wuawei phone.  I got a mate 9 ...      5  \n",
       "4  Amazing product! Took a chance on an unfamilia...      5  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating second dataframe\n",
    "electronics2 = EbayCrawler(['huawei'], 5)\n",
    "electronics2.search_word_urls()\n",
    "electronics2.find_products_urls(display=False)\n",
    "electronics2.create_reviews_df(num_to_download=5)\n",
    "electronics2.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 4) (21, 4)\n",
      "(51, 4)\n"
     ]
    }
   ],
   "source": [
    "# shapes before add\n",
    "print(electronics.df.shape, electronics2.df.shape)\n",
    "\n",
    "# adding two instances\n",
    "electronics + electronics2\n",
    "\n",
    "# shape after add\n",
    "print(electronics.df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe saved to csv file\n"
     ]
    }
   ],
   "source": [
    "#saving dataframe to csv file, a user can give some additional options regaridng saving options\n",
    "electronics.save_to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews of one product can be collected using class method\n",
    "url_test = \"\"\"\n",
    "https://www.ebay.com/p/19032164388?iid=301769309963&var=600587289314#UserReviews\n",
    "\"\"\"\n",
    "test = EbayCrawler.one_product_reviews(url_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>review title</th>\n",
       "      <th>review content</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wormer Products</td>\n",
       "      <td>Panacur C  3 packets  10 lb dog</td>\n",
       "      <td>i purchase this for my cat and chose what is a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wormer Products</td>\n",
       "      <td>use regular.. makes for healthier dogs</td>\n",
       "      <td>Works great!  no more worms and inproves breat...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wormer Products</td>\n",
       "      <td>This is a great product . After giving it to m...</td>\n",
       "      <td>Verified purchase:  Yes | Condition: new | Sol...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wormer Products</td>\n",
       "      <td>great item thank you for prompt shipping</td>\n",
       "      <td>this med is great for both dog and cat , a gre...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wormer Products</td>\n",
       "      <td>good for planaria as well</td>\n",
       "      <td>used it to deworm my fish tanks worked like a ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wormer Products</td>\n",
       "      <td>Panacur C</td>\n",
       "      <td>works every time ! read and follow directions ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wormer Products</td>\n",
       "      <td>A better product @2grams = 444mg of Fenbendazole</td>\n",
       "      <td>A better product @2grams = 444mg of Fenbendazo...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wormer Products</td>\n",
       "      <td>GREAT</td>\n",
       "      <td>Very effective. Price has doubled in the last ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wormer Products</td>\n",
       "      <td>Great product, great price !</td>\n",
       "      <td>Verified purchase:  Yes | Condition: new | Sol...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wormer Products</td>\n",
       "      <td>Will reorder</td>\n",
       "      <td>Works great, fast, no Rx needed.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wormer Products</td>\n",
       "      <td>I recommend here</td>\n",
       "      <td>Very good</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wormer Products</td>\n",
       "      <td>It works</td>\n",
       "      <td>Have it to my dog and she did good</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wormer Products</td>\n",
       "      <td>Great stuff</td>\n",
       "      <td>Thank you</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wormer Products</td>\n",
       "      <td>panacur c</td>\n",
       "      <td>well..gave to my dog... with food...they did N...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wormer Products</td>\n",
       "      <td>Good Product</td>\n",
       "      <td>This product works very well for the intended ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          category                                       review title  \\\n",
       "0  Wormer Products                    Panacur C  3 packets  10 lb dog   \n",
       "1  Wormer Products             use regular.. makes for healthier dogs   \n",
       "2  Wormer Products  This is a great product . After giving it to m...   \n",
       "3  Wormer Products           great item thank you for prompt shipping   \n",
       "4  Wormer Products                          good for planaria as well   \n",
       "5  Wormer Products                                          Panacur C   \n",
       "6  Wormer Products   A better product @2grams = 444mg of Fenbendazole   \n",
       "7  Wormer Products                                              GREAT   \n",
       "8  Wormer Products                       Great product, great price !   \n",
       "9  Wormer Products                                       Will reorder   \n",
       "0  Wormer Products                                   I recommend here   \n",
       "1  Wormer Products                                           It works   \n",
       "2  Wormer Products                                        Great stuff   \n",
       "3  Wormer Products                                          panacur c   \n",
       "4  Wormer Products                                       Good Product   \n",
       "\n",
       "                                      review content rating  \n",
       "0  i purchase this for my cat and chose what is a...      5  \n",
       "1  Works great!  no more worms and inproves breat...      5  \n",
       "2  Verified purchase:  Yes | Condition: new | Sol...      5  \n",
       "3  this med is great for both dog and cat , a gre...      5  \n",
       "4  used it to deworm my fish tanks worked like a ...      5  \n",
       "5  works every time ! read and follow directions ...      5  \n",
       "6  A better product @2grams = 444mg of Fenbendazo...      5  \n",
       "7  Very effective. Price has doubled in the last ...      5  \n",
       "8  Verified purchase:  Yes | Condition: new | Sol...      5  \n",
       "9                   Works great, fast, no Rx needed.      5  \n",
       "0                                          Very good      5  \n",
       "1                 Have it to my dog and she did good      5  \n",
       "2                                          Thank you      5  \n",
       "3  well..gave to my dog... with food...they did N...      5  \n",
       "4  This product works very well for the intended ...      5  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
