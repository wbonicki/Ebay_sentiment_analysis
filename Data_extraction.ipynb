{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extraction\n",
    "\n",
    "This notebook is the first part of the project and contains functions used for data acquisition, i.e. downloading products reviews and ratings from Ebay which is an e-commerce website (https://www.ebay.com/).\n",
    "The input data was a list containing search words (words that can be entered in a search bar). The products category was mainly focused on electronics and tools (see the search word list below). The script returns  pandas dataframe consisting of four columns: product category, raw review title, raw review content and rating.\n",
    "\n",
    "Five functions were defined:\n",
    "\n",
    " - _ebay_parser:_\n",
    " The function downloads all reviews and ratings for products that have more than one page with reviews\n",
    " \n",
    " - _ebay_parser2:_\n",
    " The function downloads all reviews and ratings for products that have only one page with reviews\n",
    " \n",
    " - _one_product_reviews:_\n",
    " The function downloads all reviews and ratings of a given product (the input argument is product url)\n",
    " \n",
    " - _review_df:_\n",
    " The function downloads all reviews and ratings for a given list with products' url\n",
    " \n",
    " - _product_collector:_\n",
    " The function collects products' urls which appear after entering a given search word in the search bar\n",
    " \n",
    "__Note:__ The notebook was run twice at different time in order to collect new reviews and ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ebay_parser(url, category=None):\n",
    "    \"\"\"\n",
    "    The function collects all reviews and ratings for a given url if a product has more than one page with reviews\n",
    "    \"\"\"\n",
    "    try:\n",
    "        content = requests.get(url).text\n",
    "    except:\n",
    "        return 'connection failed'\n",
    "    \n",
    "    review_data = pd.DataFrame(columns=['category', 'review title', 'review content', 'rating'])\n",
    "    \n",
    "    soup = BeautifulSoup(content)\n",
    "    for review, rating_stars in zip(soup.find_all('div',class_='ebay-review-section-r'), soup.find_all('span',class_='star-rating')[1:]):\n",
    "        rating = len(rating_stars.find_all('i', class_='fullStar'))\n",
    "        \n",
    "        #checkin if a review has a content and a title - if not it is skipped\n",
    "        if review.p is None or review.h3 is None: \n",
    "            continue\n",
    "        else:\n",
    "            review_data = review_data.append({'category':category, 'review title':review.h3.text, 'review content':review.p.text, 'rating':rating}, ignore_index=True)\n",
    "    \n",
    "    return review_data\n",
    "\n",
    "\n",
    "def ebay_parser2(url, category=None):\n",
    "    \"\"\"\n",
    "    The function collects all reviews and ratings for a given url if a product has only one page with reviews\n",
    "    \"\"\"\n",
    "    try:\n",
    "        content = requests.get(url).text\n",
    "    except:\n",
    "        return 'connection failed'\n",
    "    \n",
    "    review_data = pd.DataFrame(columns=['category', 'review title', 'review content', 'rating'])\n",
    "    \n",
    "    soup = BeautifulSoup(content)\n",
    "\n",
    "    \n",
    "    for review, rating_stars in zip(soup.find_all('div',class_='review--section--r'), soup.find_all('div',class_='review--section--l')):\n",
    "        rating = rating_stars.span.text[0]\n",
    "        review_data = review_data.append({'category':category, 'review title':review.h4.text, 'review content':review.p.text, 'rating':rating}, ignore_index=True)\n",
    "    \n",
    "    return review_data\n",
    "\n",
    "\n",
    "def one_product_reviews(url):\n",
    "    \"\"\"\n",
    "    This function returns pandas dataframe with reviews and rating for a given url\n",
    "    \"\"\"\n",
    "\n",
    "    isMore = True\n",
    "    content = requests.get(url).text\n",
    "    soup = BeautifulSoup(content) \n",
    "    \n",
    "    #checking if there is a link to the review section (more than 10 reviews)\n",
    "    try:\n",
    "        url = soup.find('div', class_=\"see--all--reviews\").a['href']\n",
    "    except:\n",
    "        isMore = False\n",
    "    \n",
    "    category = 'not defined'\n",
    "    try:\n",
    "        category = soup.find('nav', class_='breadcrumb clearfix').text.split('>')[-1]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #if there is more than 10 reviews\n",
    "    if isMore:\n",
    "        content = requests.get(url).text\n",
    "        soup = BeautifulSoup(content)  \n",
    "        \n",
    "\n",
    "        reviews_page_number = len(soup.find_all('a', class_='spf-link'))-2\n",
    "        if reviews_page_number == -2:\n",
    "            return ebay_parser(url+'?pgn=1')\n",
    "        else:\n",
    "            for page in range(1, reviews_page_number+1):\n",
    "                url_temp = url + f'?pgn={page}'\n",
    "                if page == 1:\n",
    "                    reviews = ebay_parser(url_temp, category)\n",
    "                else:\n",
    "                    reviews = pd.concat((reviews, ebay_parser(url_temp, category)))\n",
    "            return reviews\n",
    "    \n",
    "    #if there is less than 11 reviews\n",
    "    else:\n",
    "        return ebay_parser2(url, category)\n",
    "    \n",
    "    \n",
    "def review_df(url_list):\n",
    "    \"\"\"\n",
    "    This function receives a list with urls and returns one dataframe with reviews and ratings\n",
    "    \"\"\" \n",
    "    df = one_product_reviews(url_list[0])\n",
    "    for product in url_list[1:]:\n",
    "        df = pd.concat((df, one_product_reviews(product)))\n",
    "    df.set_index(np.arange(df.shape[0]), inplace=True)\n",
    "    return df\n",
    "\n",
    "def product_collector(url):\n",
    "    \"\"\"\n",
    "    The function receives an url with search word results and collects reviews and ratings of searched products\n",
    "    \"\"\"\n",
    "    links_list = []\n",
    "    soup = BeautifulSoup(requests.get(url).text)\n",
    "    for link in soup.find_all('div', class_='s-item__reviews'):\n",
    "        links_list.append(link.a['href'])\n",
    "            \n",
    "    return links_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search words and loop for collecting products urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_search=['iphone, xbox, playstation','sony', 'samsung', 'apple', \n",
    "              'lenovo', 'asus', 'dell', 'acer', 'HP', 'toshiba', \n",
    "              'philips','denon','canon','gopro','xiaomi','google', \n",
    "              'monitor', 'keyboard', 'mouse','headphones','cable', 'set', \n",
    "              'tool','tools','saw', 'drill', 'game', 'car','kitchen']\n",
    "\n",
    "for word in final_search:\n",
    "    for i in range(1,100):     \n",
    "        #this is an i-th page with search results for a given word\n",
    "        url = f'https://www.ebay.com/sch/i.html?_from=R40&_nkw={word}&_sacat=0&_pgn={i}'\n",
    "        list_temp = product_collector(url) \n",
    "        final_list.extend(list_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1653"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of products\n",
    "len(final_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting reviews and ratings is divided into many steps to get a better control on the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = review_df(final_list[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = review_df(final_list[100:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = review_df(final_list[250:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = review_df(final_list[400:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = review_df(final_list[500:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = review_df(final_list[600:800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = review_df(final_list[800:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = review_df(final_list[1000:1200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = review_df(final_list[1200:1400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10 = review_df(final_list[1400:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>review title</th>\n",
       "      <th>review content</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Headsets</td>\n",
       "      <td>Wireless gaming headset</td>\n",
       "      <td>This gaming headset ticks all the boxes # look...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Headsets</td>\n",
       "      <td>Cheap, not great, but good enough.</td>\n",
       "      <td>I don't want to be too harsh because it's reas...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Headsets</td>\n",
       "      <td>MezumiWireless Gaming Headset</td>\n",
       "      <td>I originally bought this wireless headset for ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Headsets</td>\n",
       "      <td>Good for those with a big head, low budget</td>\n",
       "      <td>Easy setup, rated for 6 hours battery but mine...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Headsets</td>\n",
       "      <td>HW- S2 great headset.</td>\n",
       "      <td>This is my 2nd Mezumi headset, It kills the fi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50150</th>\n",
       "      <td>Racks &amp; Holders</td>\n",
       "      <td>Utensil holder</td>\n",
       "      <td>Reasonably priced but a little flimsy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50151</th>\n",
       "      <td>Racks &amp; Holders</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>As described</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50152</th>\n",
       "      <td>Racks &amp; Holders</td>\n",
       "      <td>cheap looking</td>\n",
       "      <td>cheap looking</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50153</th>\n",
       "      <td>Racks &amp; Holders</td>\n",
       "      <td>Ok</td>\n",
       "      <td>Okay</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50154</th>\n",
       "      <td>Racks &amp; Holders</td>\n",
       "      <td>Cooking utensils</td>\n",
       "      <td>Are goodg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50155 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              category                                review title  \\\n",
       "0             Headsets                    Wireless gaming headset    \n",
       "1             Headsets          Cheap, not great, but good enough.   \n",
       "2             Headsets               MezumiWireless Gaming Headset   \n",
       "3             Headsets  Good for those with a big head, low budget   \n",
       "4             Headsets                       HW- S2 great headset.   \n",
       "...                ...                                         ...   \n",
       "50150  Racks & Holders                              Utensil holder   \n",
       "50151  Racks & Holders                                 Recommended   \n",
       "50152  Racks & Holders                               cheap looking   \n",
       "50153  Racks & Holders                                          Ok   \n",
       "50154  Racks & Holders                            Cooking utensils   \n",
       "\n",
       "                                          review content rating  \n",
       "0      This gaming headset ticks all the boxes # look...      5  \n",
       "1      I don't want to be too harsh because it's reas...      3  \n",
       "2      I originally bought this wireless headset for ...      5  \n",
       "3      Easy setup, rated for 6 hours battery but mine...      3  \n",
       "4      This is my 2nd Mezumi headset, It kills the fi...      5  \n",
       "...                                                  ...    ...  \n",
       "50150              Reasonably priced but a little flimsy      3  \n",
       "50151                                       As described      5  \n",
       "50152                                      cheap looking      1  \n",
       "50153                                               Okay      5  \n",
       "50154                                          Are goodg      4  \n",
       "\n",
       "[50155 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9,df10])\n",
    "data.set_index(np.arange(data.shape[0]), inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the dataframe to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "date='30122020'\n",
    "\n",
    "data.to_csv(f'ebay_reviews{date}.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
